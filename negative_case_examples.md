# Negative Case Examples

Some case examples that have been mentioned by folks working on issues of bias in the AI and closely related space. These categories are not mutually exclusive, and the entries currently listed may fit in other categories they're not currently listed in as well. I'll want to organize these more and think more closely about better ways to effectively arrange all of these.

### Predictive Policing

* [Machine Bias (COMPAS)](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing) (2016)
* [To Predict and Serve (Oakland Overpolicing & PredPol)](https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1740-9713.2016.00960.x) (2016)
* [HunchLab](https://www.themarshallproject.org/2016/02/03/policing-the-future?ref=hp-2-111#.UyhBLnmlj) (2016)
* [The Rise of Big Data Policing](https://nyupress.org/books/9781479892822/) (2017)

### Computer Vision

* [Nikon Face Detection](http://content.time.com/time/business/article/0,8599,1954643,00.html) (2010)
* [Google Racist Autotagging ("Gorillas")](https://www.theguardian.com/technology/2015/jul/01/google-sorry-racist-auto-tag-photo-app) (2015)
* [Gender Shades](http://gendershades.org) (2018)

### Natural Language Processing

* [Gendered Google Translate](http://genderedinnovations.stanford.edu/case-studies/nlp.html#tabs-2) (2012)
* [Microsoft's Tay Twitter AI](https://www.theguardian.com/technology/2016/mar/24/tay-microsofts-ai-chatbot-gets-a-crash-course-in-racism-from-twitter) (2016)
* [Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings](https://arxiv.org/pdf/1607.06520.pdf) (2016)
* [Racial Disparity in NLP (AAVE Recognition)](http://brenocon.com/oconnor_fatml_aae_20170814.pdf) (2017)
* [Gender-Neutral to Gendered Translations (Turkish "He is a doctor")](https://www.facebook.com/photo.php?fbid=10154851496086949&set=a.10150241543551949.318652.661666948&type=3&theater) (2017)
* [Accent Bias](https://www.youtube.com/watch?v=gJCVla9xYUs) (Book chapter forthcoming)

### Proxies

* [Amazon Same-Day Delivery](https://www.bloomberg.com/graphics/2016-amazon-same-day/) (2016)

### Recommendation Systems and Search

* [Discrimination in Online Ad Delivery](https://dataprivacylab.org/projects/onlineads/index.html) (2013)
* [LinkedIn Gendered "Did You Mean" Search](https://www.seattletimes.com/business/microsoft/how-linkedins-search-engine-may-reflect-a-bias/) (2016)
* [Algorithms of Oppression](https://nyupress.org/books/9781479837243/) (2017)

### Representation

* Search results for 'professor' or 'engineer' or 'robot'

### General

* [Weapons of Math Destruction](https://weaponsofmathdestructionbook.com) (2016)
* [Technically Wrong](http://books.wwnorton.com/books/978-0-393-63463-1/) (2017)
* [Automating Inequality](https://us.macmillan.com/books/9781250074317) (2017)
